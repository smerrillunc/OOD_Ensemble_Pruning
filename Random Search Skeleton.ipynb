{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ffdd80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from Clustering import Clustering\n",
    "from DataNoiseAdder import DataNoiseAdder\n",
    "from DatasetCorruptor import DatasetCorruptor\n",
    "from DecisionTreeEnsemble import DecisionTreeEnsemble\n",
    "from SyntheticDataGenerator import SyntheticDataGenerator\n",
    "from EnsembleDiversity import EnsembleDiversity\n",
    "from EnsembleMetrics import EnsembleMetrics\n",
    "\n",
    "from utils import get_dataset, get_ensemble_preds_from_models, get_precision_recall_auc, auprc_threshs\n",
    "from utils import plot_precision_recall, plot_aroc_at_curve, fitness_scatter\n",
    "from utils import compute_metrics_in_buckets, flatten_df, compute_cluster_metrics\n",
    "from utils import get_categorical_and_float_features\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258423e4",
   "metadata": {},
   "source": [
    "### Experiment Args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f307604",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {}\n",
    "args['ntrls'] = 10\n",
    "args['ensemble_size'] = 10\n",
    "args['dataset_path'] = \"/Users/scottmerrill/Documents/UNC/Research/OOD-Ensembles/datasets\"\n",
    "args['dataset_name'] = 'heloc_tf' \n",
    "\n",
    "# Decision Tree/Model Pool Params\n",
    "args['num_classifiers'] = 100\n",
    "args['feature_fraction'] = 0.5\n",
    "args['data_fraction'] = 0.8\n",
    "args['max_depth'] = 10\n",
    "args['min_samples_leaf'] = 5\n",
    "args['random_state'] = 1\n",
    "args['clusters_list'] = [3]\n",
    "args['shift_feature_count'] = 5\n",
    "\n",
    "AUCTHRESHS = np.array([0.1, 0.2, 0.3, 0.4, 1. ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce87de2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_val_id, y_val_id, x_val_ood, y_val_ood = get_dataset(args['dataset_path'] , args['dataset_name'])\n",
    "num_features = x_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a33f186",
   "metadata": {},
   "source": [
    "### Building and Training Model Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f60bfaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pool = DecisionTreeEnsemble(args['num_classifiers'], \n",
    "                                  args['feature_fraction'],\n",
    "                                  args['data_fraction'],\n",
    "                                  args['max_depth'],\n",
    "                                  args['min_samples_leaf'],\n",
    "                                  args['random_state'])\n",
    "\n",
    "# train model pool\n",
    "model_pool.train(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e1084d",
   "metadata": {},
   "source": [
    "### Caching Model Pool Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8bff972",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pool_preds = model_pool.predict(x_val_ood)\n",
    "model_pool_pred_probs = model_pool.predict_proba(x_val_ood)\n",
    "mp_precision, mp_recall, mp_auc = get_precision_recall_auc(model_pool_pred_probs, y_val_ood, AUCTHRESHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42afc68",
   "metadata": {},
   "source": [
    "### Caching Individual Model Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26c7e12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pool.train_preds = model_pool.get_individual_predictions(x_train).T\n",
    "model_pool.train_pred_probs = model_pool.get_individual_probabilities(x_train)\n",
    "\n",
    "model_pool.val_id_preds = model_pool.get_individual_predictions(x_val_id).T\n",
    "model_pool.val_id_pred_probs = model_pool.get_individual_probabilities(x_val_id)\n",
    "\n",
    "model_pool.val_ood_preds = model_pool.get_individual_predictions(x_val_ood).T\n",
    "model_pool.val_ood_pred_probs = model_pool.get_individual_probabilities(x_val_ood)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb0f4d6",
   "metadata": {},
   "source": [
    "### Clustering Data into different groupings and preparing formating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af7e516f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_dict = {}\n",
    "\n",
    "clustering = Clustering(x_train)\n",
    "for num_clusters in args['clusters_list']:\n",
    "    kmean_labels = clustering.k_means(n_clusters=num_clusters)\n",
    "    hier_labels = clustering.hierarchical_clustering(n_clusters=num_clusters)\n",
    "    gmm_labels = clustering.gaussian_mixture(n_components=num_clusters)\n",
    "    spectral_labels = clustering.spectral_clustering(n_clusters=num_clusters)\n",
    "    clusters_dict[f'kmeans_{num_clusters}_train'] = kmean_labels\n",
    "    clusters_dict[f'hier_{num_clusters}_train'] = hier_labels\n",
    "    clusters_dict[f'gmm_{num_clusters}_train'] = gmm_labels\n",
    "    clusters_dict[f'spectral_{num_clusters}_train'] = spectral_labels\n",
    "\n",
    "clustering = Clustering(x_val_id)\n",
    "for num_clusters in args['clusters_list']:\n",
    "    kmean_labels = clustering.k_means(n_clusters=num_clusters)\n",
    "    hier_labels = clustering.hierarchical_clustering(n_clusters=num_clusters)\n",
    "    gmm_labels = clustering.gaussian_mixture(n_components=num_clusters)\n",
    "    spectral_labels = clustering.spectral_clustering(n_clusters=num_clusters)\n",
    "    clusters_dict[f'kmeans_{num_clusters}_val'] = kmean_labels\n",
    "    clusters_dict[f'hier_{num_clusters}_val'] = hier_labels\n",
    "    clusters_dict[f'gmm_{num_clusters}_val'] = gmm_labels\n",
    "    clusters_dict[f'spectral_{num_clusters}_val'] = spectral_labels\n",
    "    \n",
    "    \n",
    "dbscan_labels = clustering.dbscan()\n",
    "mean_shift_labels = clustering.mean_shift()\n",
    "\n",
    "dbscan_val_labels = clustering.dbscan()\n",
    "mean_shift_val_labels = clustering.mean_shift()\n",
    "\n",
    "clusters_dict[f'dbscan_train'] = dbscan_labels\n",
    "clusters_dict[f'dbscan_val'] = mean_shift_val_labels\n",
    "clusters_dict[f'meanshift_train'] = mean_shift_labels\n",
    "clusters_dict[f'meanshift_val'] = mean_shift_val_labels\n",
    "\n",
    "clusters_dict_train = {k: v for k, v in clusters_dict.items() if '_train' in k}\n",
    "clusters_dict_val = {k: v for k, v in clusters_dict.items() if '_val' in k}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "478bcbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert x_train and y_train to DataFrames (assuming x_train has multiple features)\n",
    "x_train_df = pd.DataFrame(x_train)\n",
    "y_train_df = pd.Series(y_train)\n",
    "\n",
    "# Concatenate x_train_df and y_train_df\n",
    "data = pd.concat([x_train_df, y_train_df], axis=1)\n",
    "\n",
    "# Calculate correlation matrix\n",
    "correlation_matrix = data.corr()\n",
    "\n",
    "# Extract correlations between each feature and the target variable (y_train is the last column)\n",
    "correlations_with_target = correlation_matrix.iloc[:-1, -1]\n",
    "\n",
    "# Sort correlations in descending order\n",
    "sorted_correlations = correlations_with_target.abs().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "535a397c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we ill add noise to these features\n",
    "categorical_cols, float_cols = get_categorical_and_float_features(x_train)\n",
    "\n",
    "add_nosie_feats = sorted_correlations.index[:args['shift_feature_count'] ]\n",
    "\n",
    "add_nosie_feats_float = [x for x in add_nosie_feats if x in float_cols]\n",
    "add_nosie_feats_categorical = [x for x in add_nosie_feats if x in categorical_cols]\n",
    "\n",
    "train_noise = DataNoiseAdder(x_train)\n",
    "val_noise = DataNoiseAdder(x_val_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f41dfd5",
   "metadata": {},
   "source": [
    "## Noise Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3c8499",
   "metadata": {},
   "source": [
    "### Guassian Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1386ba10",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_noise = train_noise.add_gaussian_noise(add_nosie_feats_float)\n",
    "x_train_noise = train_noise.add_categorical_noise(add_nosie_feats_categorical)\n",
    "\n",
    "x_val_noise = val_noise.add_gaussian_noise(add_nosie_feats_float)\n",
    "x_val_noise = val_noise.add_categorical_noise(add_nosie_feats_categorical)\n",
    "\n",
    "model_pool.train_gaussian_preds = model_pool.get_individual_predictions(x_train_noise).T\n",
    "model_pool.train_gaussian_pred_probs = model_pool.get_individual_probabilities(x_train_noise)\n",
    "\n",
    "model_pool.val_gaussian_preds = model_pool.get_individual_predictions(x_val_noise).T\n",
    "model_pool.val_gaussian_pred_probs = model_pool.get_individual_probabilities(x_val_noise)\n",
    "del x_train_noise, x_val_noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5604a969",
   "metadata": {},
   "source": [
    "### Uniform Noise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ff9b20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_noise = train_noise.add_uniform_noise(add_nosie_feats_float)\n",
    "x_train_noise = train_noise.add_categorical_noise(add_nosie_feats_categorical)\n",
    "\n",
    "x_val_noise = val_noise.add_uniform_noise(add_nosie_feats_float)\n",
    "x_val_noise = val_noise.add_categorical_noise(add_nosie_feats_categorical)\n",
    "\n",
    "model_pool.train_uniform_preds = model_pool.get_individual_predictions(x_train_noise).T\n",
    "model_pool.train_uniform_pred_probs = model_pool.get_individual_probabilities(x_train_noise)\n",
    "\n",
    "model_pool.val_uniform_preds = model_pool.get_individual_predictions(x_val_noise).T\n",
    "model_pool.val_uniform_pred_probs = model_pool.get_individual_probabilities(x_val_noise)\n",
    "del x_train_noise, x_val_noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0a49ac",
   "metadata": {},
   "source": [
    "### Laplace Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee926ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_noise = train_noise.add_laplace_noise(add_nosie_feats_float)\n",
    "x_train_noise = train_noise.add_categorical_noise(add_nosie_feats_categorical)\n",
    "\n",
    "x_val_noise = val_noise.add_laplace_noise(add_nosie_feats_float)\n",
    "x_val_noise = val_noise.add_categorical_noise(add_nosie_feats_categorical)\n",
    "\n",
    "model_pool.train_laplace_preds = model_pool.get_individual_predictions(x_train_noise).T\n",
    "model_pool.train_laplace_pred_probs = model_pool.get_individual_probabilities(x_train_noise)\n",
    "\n",
    "model_pool.val_laplace_preds = model_pool.get_individual_predictions(x_val_noise).T\n",
    "model_pool.val_laplace_pred_probs = model_pool.get_individual_probabilities(x_val_noise)\n",
    "del x_train_noise, x_val_noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07c3f31",
   "metadata": {},
   "source": [
    "### Dropout Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "592d26d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_noise = train_noise.add_dropout_noise(add_nosie_feats_float)\n",
    "x_train_noise = train_noise.add_categorical_noise(add_nosie_feats_categorical)\n",
    "\n",
    "x_val_noise = val_noise.add_dropout_noise(add_nosie_feats_float)\n",
    "x_val_noise = val_noise.add_categorical_noise(add_nosie_feats_categorical)\n",
    "\n",
    "model_pool.train_dropout_preds = model_pool.get_individual_predictions(x_train_noise).T\n",
    "model_pool.train_dropout_pred_probs = model_pool.get_individual_probabilities(x_train_noise)\n",
    "\n",
    "model_pool.val_dropout_preds = model_pool.get_individual_predictions(x_val_noise).T\n",
    "model_pool.val_dropout_pred_probs = model_pool.get_individual_probabilities(x_val_noise)\n",
    "del x_train_noise, x_val_noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2370563",
   "metadata": {},
   "source": [
    "### Boundary Shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb40b619",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_noise = train_noise.add_concept_shift(shift_type=\"boundary_shift\",\n",
    "                                             shift_params={'feature_col':float_cols[0]})\n",
    "x_train_noise = train_noise.add_categorical_noise(add_nosie_feats_categorical)\n",
    "\n",
    "x_val_noise = val_noise.add_concept_shift(shift_type=\"boundary_shift\",\n",
    "                                             shift_params={'feature_col':float_cols[0]})\n",
    "x_val_noise = val_noise.add_categorical_noise(add_nosie_feats_categorical)\n",
    "\n",
    "model_pool.train_boundaryshift_preds = model_pool.get_individual_predictions(x_train_noise).T\n",
    "model_pool.train_boundaryshift_pred_probs = model_pool.get_individual_probabilities(x_train_noise)\n",
    "\n",
    "model_pool.val_boundaryshift_preds = model_pool.get_individual_predictions(x_val_noise).T\n",
    "model_pool.val_boundaryshift_pred_probs = model_pool.get_individual_probabilities(x_val_noise)\n",
    "del x_train_noise, x_val_noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deec62f9",
   "metadata": {},
   "source": [
    "### Scaling Shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2be440a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_noise = train_noise.add_covariate_shift(add_nosie_feats_float, \n",
    "                                shift_type='scaling',\n",
    "                                shift_params = {'scale_factor':1.2})\n",
    "\n",
    "\n",
    "x_val_noise = val_noise.add_covariate_shift(add_nosie_feats_float, \n",
    "                                shift_type='scaling',\n",
    "                                shift_params = {'scale_factor':1.2})\n",
    "\n",
    "model_pool.train_upscaleshift_preds = model_pool.get_individual_predictions(x_train_noise).T\n",
    "model_pool.train_upscaleshift_pred_probs = model_pool.get_individual_probabilities(x_train_noise)\n",
    "\n",
    "model_pool.val_upscaleshift_preds = model_pool.get_individual_predictions(x_val_noise).T\n",
    "model_pool.val_upscaleshift_pred_probs = model_pool.get_individual_probabilities(x_val_noise)\n",
    "del x_train_noise, x_val_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0acaf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_noise = train_noise.add_covariate_shift(add_nosie_feats_float, \n",
    "                                shift_type='scaling',\n",
    "                                shift_params = {'scale_factor':0.8})\n",
    "\n",
    "\n",
    "x_val_noise = val_noise.add_covariate_shift(add_nosie_feats_float, \n",
    "                                shift_type='scaling',\n",
    "                              shift_params = {'scale_factor':0.8})\n",
    "\n",
    "model_pool.train_downscaleshift_preds = model_pool.get_individual_predictions(x_train_noise).T\n",
    "model_pool.train_downscaleshift_pred_probs = model_pool.get_individual_probabilities(x_train_noise)\n",
    "\n",
    "model_pool.val_downscaleshift_preds = model_pool.get_individual_predictions(x_val_noise).T\n",
    "model_pool.val_downscaleshift_pred_probs = model_pool.get_individual_probabilities(x_val_noise)\n",
    "del x_train_noise, x_val_noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f680e357",
   "metadata": {},
   "source": [
    "### Distribution shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1cec1af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_noise = train_noise.add_covariate_shift(add_nosie_feats_float, \n",
    "                                shift_type='distribution',\n",
    "                                shift_params = {'dist_type':'uniform'})\n",
    "x_val_noise = val_noise.add_covariate_shift(add_nosie_feats_float, \n",
    "                                shift_type='distribution',\n",
    "                                shift_params = {'dist_type':'uniform'})\n",
    "\n",
    "model_pool.train_distshiftuniform_preds = model_pool.get_individual_predictions(x_train_noise).T\n",
    "model_pool.train_distshiftuniform_pred_probs = model_pool.get_individual_probabilities(x_train_noise)\n",
    "\n",
    "model_pool.val_distshiftuniform_preds = model_pool.get_individual_predictions(x_val_noise).T\n",
    "model_pool.val_distshiftuniform_pred_probs = model_pool.get_individual_probabilities(x_val_noise)\n",
    "del x_train_noise, x_val_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "136b6145",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_noise = train_noise.add_covariate_shift(add_nosie_feats_float, \n",
    "                                shift_type='distribution',\n",
    "                                shift_params = {'dist_type':'normal'})\n",
    "\n",
    "\n",
    "x_val_noise = val_noise.add_covariate_shift(add_nosie_feats_float, \n",
    "                                shift_type='distribution',\n",
    "                                shift_params = {'dist_type':'normal'})\n",
    "\n",
    "x_train_noise = train_noise.add_covariate_shift(add_nosie_feats_float, \n",
    "                                shift_type='distribution',\n",
    "                                shift_params = {'dist_type':'uniform'})\n",
    "x_val_noise = val_noise.add_covariate_shift(add_nosie_feats_float, \n",
    "                                shift_type='distribution',\n",
    "                                shift_params = {'dist_type':'uniform'})\n",
    "\n",
    "model_pool.train_distshiftgaussian_preds = model_pool.get_individual_predictions(x_train_noise).T\n",
    "model_pool.train_distshiftgaussian_pred_probs = model_pool.get_individual_probabilities(x_train_noise)\n",
    "\n",
    "model_pool.val_distshiftgaussian_preds = model_pool.get_individual_predictions(x_val_noise).T\n",
    "model_pool.val_distshiftgaussian_pred_probs = model_pool.get_individual_probabilities(x_val_noise)\n",
    "del x_train_noise, x_val_noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d319b260",
   "metadata": {},
   "source": [
    "### Label Shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "384ca5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_flipped = DataNoiseAdder.label_flip(y_train)\n",
    "y_val_flipped = DataNoiseAdder.label_flip(y_val_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c1ff75",
   "metadata": {},
   "source": [
    "### Random Search Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4ff46488",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [x for x in dir(model_pool) if 'preds' in x]\n",
    "b = [x for x in dir(model_pool) if 'pred_' in x]\n",
    "a.remove('val_ood_preds')\n",
    "b.remove('val_ood_pred_probs')\n",
    "pred_attributes = [(a[i], b[i], a[i].split('_')[0]+'_'+a[i].split('_')[1]) for i in range(len(a))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "59254f80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1377,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_id.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "22017d76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ee2e101b7ca432da52c951cf430fac6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "precisions_df = pd.DataFrame()\n",
    "recalls_df = pd.DataFrame()\n",
    "aucs_df = pd.DataFrame()\n",
    "fitness_df = pd.DataFrame()\n",
    "\n",
    "for trial in tqdm(range(args['ntrls'])):\n",
    "    indices = np.random.choice(model_pool.num_classifiers, size=args['ensemble_size'], replace=True)\n",
    "\n",
    "    # ood preds of sub-ensemble\n",
    "    ood_preds, ood_pred_probs = get_ensemble_preds_from_models(model_pool.val_ood_pred_probs[indices])\n",
    "\n",
    "    # save OOD precision/recalls seprately\n",
    "    precision, recall, auc = get_precision_recall_auc(ood_pred_probs, y_val_ood, AUCTHRESHS)\n",
    "\n",
    "    recalls_df = pd.concat([recalls_df, pd.DataFrame(recall)], axis=1)\n",
    "    precisions_df = pd.concat([precisions_df, pd.DataFrame(precision)], axis=1)\n",
    "    aucs_df = pd.concat([aucs_df, pd.DataFrame(auc)], axis=1)\n",
    "\n",
    "    tmp = {'generation':trial,\n",
    "              'ensemble_files':','.join(str(x) for x in indices)}\n",
    "    cluster_metrics = pd.DataFrame()\n",
    "\n",
    "    # Compute all Fitness Metrics\n",
    "    for label_flip in [0, 1]:\n",
    "        for pred_tuple in pred_attributes:\n",
    "            preds_name, pred_prob_name, prefix_name = pred_tuple\n",
    "\n",
    "            if 'train' in prefix_name:\n",
    "                if label_flip:\n",
    "                    Y = y_train_flipped\n",
    "                    prefix_name = prefix_name + '_flip'\n",
    "                else:\n",
    "                    Y = y_train\n",
    "                    \n",
    "                clusters_dict = clusters_dict_train\n",
    "            else:\n",
    "                if label_flip:\n",
    "                    prefix_name = prefix_name + '_flip'\n",
    "                    Y = y_val_flipped\n",
    "                else:\n",
    "                    Y = y_val_id\n",
    "\n",
    "                clusters_dict = clusters_dict_val\n",
    "\n",
    "            model_pool_preds = getattr(model_pool, preds_name)\n",
    "            model_pool_pred_probs = getattr(model_pool, pred_prob_name)\n",
    "\n",
    "            model_preds = model_pool_preds[indices]\n",
    "            model_pred_probs = model_pool_pred_probs[indices]\n",
    "\n",
    "            # id val preds of sub-ensemble\n",
    "            ensemble_preds, ensemble_pred_probs = get_ensemble_preds_from_models(model_pred_probs)\n",
    "            metrics = EnsembleMetrics(Y, ensemble_preds, ensemble_pred_probs[:,1])\n",
    "            diversity = EnsembleDiversity(Y, model_preds)\n",
    "\n",
    "            tmp.update({f'{prefix_name}_acc':metrics.accuracy(),\n",
    "                   f'{prefix_name}_auc':metrics.auc(),\n",
    "                   f'{prefix_name}_prec':metrics.precision(),\n",
    "                   f'{prefix_name}_rec':metrics.recall(),\n",
    "                   f'{prefix_name}_f1':metrics.f1(),\n",
    "                   f'{prefix_name}_mae':metrics.mean_absolute_error(),\n",
    "                   f'{prefix_name}_mse':metrics.mean_squared_error(),\n",
    "                   f'{prefix_name}_logloss':metrics.log_loss(),\n",
    "\n",
    "                   # diversity\n",
    "                   f'{prefix_name}_q_statistic':np.mean(diversity.q_statistic()),\n",
    "                   f'{prefix_name}_correlation_coefficient':np.mean(diversity.correlation_coefficient()),\n",
    "                   f'{prefix_name}_entropy':np.mean(diversity.entropy()),\n",
    "                   f'{prefix_name}_diversity_measure':diversity.diversity_measure(),\n",
    "                   f'{prefix_name}_hamming_distance':np.mean(diversity.hamming_distance()),\n",
    "                   f'{prefix_name}_error_rate':np.mean(diversity.error_rate()),\n",
    "                   f'{prefix_name}_auc':np.mean(diversity.auc()),\n",
    "                   f'{prefix_name}_brier_score':np.mean(diversity.brier_score()),\n",
    "                   f'{prefix_name}_ensemble_variance':np.mean(diversity.ensemble_variance()),\n",
    "                  })\n",
    "\n",
    "            # compute cluster metrics\n",
    "            tmp_cluster = compute_cluster_metrics(clusters_dict, ensemble_preds, model_preds, model_pred_probs, Y)\n",
    "            col_names = [prefix_name + '_' + x for x in tmp_cluster.columns]\n",
    "            col_names = [name.replace('_val_acc', '') for name in col_names]\n",
    "            col_names = [name.replace('_train_acc', '') for name in col_names]\n",
    "            tmp_cluster.columns = col_names\n",
    "\n",
    "            cluster_metrics = pd.concat([cluster_metrics, tmp_cluster], axis=1)\n",
    "\n",
    "    raw_metrics = pd.DataFrame([tmp])    \n",
    "    tmp = pd.concat([raw_metrics, cluster_metrics], axis=1)\n",
    "    fitness_df = pd.concat([fitness_df, tmp])\n",
    "    #precisions_df.to_csv(save_path+'/precisions_df.csv', index=False)\n",
    "    #recalls_df.to_csv(save_path+'/recalls_df.csv', index=False)\n",
    "    #aucs_df.to_csv(save_path+'/aucs_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ebd965",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa059c42",
   "metadata": {},
   "source": [
    "### Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c86fd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitness_df = fitness_df.reset_index(drop=True)\n",
    "best_fitness_index = {i+1:index for i,index in enumerate(fitness_df.nlargest(3, 'val_upscaleshift_meanshift_val_error_rate_mean').index)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b386f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "plot_precision_recall(precisions_df, recalls_df, mp_precision, mp_recall, best_fitness_index, ax=axs[0])\n",
    "plot_aroc_at_curve(AUCTHRESHS, aucs_df, mp_auc, best_fitness_index, ax=axs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4380ba38",
   "metadata": {},
   "source": [
    "### Fitness Function Diagnosis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbc4f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['train_boundaryshift_acc', 'val_upscaleshift_meanshift_val_error_rate_mean']\n",
    "fig, axs = plt.subplots(1, len(cols), figsize=(12, 6))\n",
    "\n",
    "for idx, col in enumerate(cols):\n",
    "    # Plot AUC scatter for different fitness columns\n",
    "    fitness_scatter(fitness_df, aucs_df, col, ax=axs[idx])\n",
    "plt.tight_layout(pad=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4835c8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns',None)\n",
    "fitness_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bee31d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
