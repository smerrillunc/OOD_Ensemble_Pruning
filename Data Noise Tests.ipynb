{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ffdd80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from Clustering import Clustering\n",
    "from DataNoiseAdder import DataNoiseAdder\n",
    "from DatasetCorruptor import DatasetCorruptor\n",
    "from DecisionTreeEnsemble import DecisionTreeEnsemble\n",
    "from SyntheticDataGenerator import SyntheticDataGenerator\n",
    "from EnsembleDiversity import EnsembleDiversity\n",
    "from EnsembleMetrics import EnsembleMetrics\n",
    "\n",
    "from utils import get_dataset, get_ensemble_preds_from_models, get_precision_recall_auc, auprc_threshs\n",
    "from utils import plot_precision_recall, plot_aroc_at_curve, fitness_scatter\n",
    "from utils import compute_metrics_in_buckets, flatten_df, compute_cluster_metrics\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258423e4",
   "metadata": {},
   "source": [
    "### Experiment Args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f307604",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {}\n",
    "args['ntrls'] = 10\n",
    "args['ensemble_size'] = 10\n",
    "args['dataset_path'] = \"/Users/scottmerrill/Documents/UNC/Research/OOD-Ensembles/datasets\"\n",
    "args['dataset_name'] = 'german' \n",
    "\n",
    "# Decision Tree/Model Pool Params\n",
    "args['num_classifiers'] = 100\n",
    "args['feature_fraction'] = 0.5\n",
    "args['data_fraction'] = 0.8\n",
    "args['max_depth'] = 10\n",
    "args['min_samples_leaf'] = 5\n",
    "args['random_state'] = 1\n",
    "args['clusters_list'] = [3]\n",
    "args['shift_feature_count'] = 5\n",
    "\n",
    "AUCTHRESHS = np.array([0.1, 0.2, 0.3, 0.4, 1. ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "121612ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_val_id, y_val_id, x_val_ood, y_val_ood = get_dataset(args['dataset_path'] , args['dataset_name'])\n",
    "num_features = x_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31679e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pool = DecisionTreeEnsemble(args['num_classifiers'], \n",
    "                                  args['feature_fraction'],\n",
    "                                  args['data_fraction'],\n",
    "                                  args['max_depth'],\n",
    "                                  args['min_samples_leaf'],\n",
    "                                  args['random_state'])\n",
    "\n",
    "# train model pool\n",
    "model_pool.train(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f58bf02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_categorical_and_float_features(data, unique_threshold=10):\n",
    "    \"\"\"\n",
    "    Separate categorical and float features based on the number of unique values.\n",
    "    \n",
    "    - data: numpy array (rows: samples, cols: features)\n",
    "    - unique_threshold: max number of unique values to consider a feature as categorical\n",
    "    \n",
    "    Returns:\n",
    "    - categorical_features: list of indices for categorical features\n",
    "    - float_features: list of indices for float (continuous) features\n",
    "    \"\"\"\n",
    "    categorical_features = []\n",
    "    float_features = []\n",
    "\n",
    "    # Iterate over each column\n",
    "    for col in range(data.shape[1]):\n",
    "        unique_values = np.unique(data[:, col])\n",
    "        if len(unique_values) <= unique_threshold:\n",
    "            categorical_features.append(col)  # Consider it categorical if the unique values are below the threshold\n",
    "        else:\n",
    "            float_features.append(col)  # Otherwise, it's treated as a float/continuous feature\n",
    "\n",
    "    return categorical_features, float_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c38fe6",
   "metadata": {},
   "source": [
    "## Get most correlated shift count features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e2cb4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert x_train and y_train to DataFrames (assuming x_train has multiple features)\n",
    "x_train_df = pd.DataFrame(x_train)\n",
    "y_train_df = pd.Series(y_train)\n",
    "\n",
    "# Concatenate x_train_df and y_train_df\n",
    "data = pd.concat([x_train_df, y_train_df], axis=1)\n",
    "\n",
    "# Calculate correlation matrix\n",
    "correlation_matrix = data.corr()\n",
    "\n",
    "# Extract correlations between each feature and the target variable (y_train is the last column)\n",
    "correlations_with_target = correlation_matrix.iloc[:-1, -1]\n",
    "\n",
    "# Sort correlations in descending order\n",
    "sorted_correlations = correlations_with_target.abs().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b462c7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we ill add noise to these features\n",
    "categorical_cols, float_cols = get_categorical_and_float_features(x_train)\n",
    "\n",
    "add_nosie_feats = sorted_correlations.index[:args['shift_feature_count'] ]\n",
    "\n",
    "add_nosie_feats_float = [x for x in add_nosie_feats if x in float_cols]\n",
    "add_nosie_feats_categorical = [x for x in add_nosie_feats if x in categorical_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "457a2618",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 6, 10, 26]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_nosie_feats_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d0b1af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_noise = DataNoiseAdder(x_train)\n",
    "val_noise = DataNoiseAdder(x_val_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27abc05",
   "metadata": {},
   "source": [
    "### Guassian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e935b86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_noise = train_noise.add_gaussian_noise(add_nosie_feats_float)\n",
    "x_train_noise = train_noise.add_categorical_noise(add_nosie_feats_categorical)\n",
    "\n",
    "x_val_noise = val_noise.add_gaussian_noise(add_nosie_feats_float)\n",
    "x_val_noise = val_noise.add_categorical_noise(add_nosie_feats_categorical)\n",
    "\n",
    "model_pool.train_gaussian_preds = model_pool.get_individual_predictions(x_train_noise).T\n",
    "model_pool.train_gaussian_pred_probs = model_pool.get_individual_probabilities(x_train_noise)\n",
    "\n",
    "model_pool.val_gaussian_preds = model_pool.get_individual_predictions(x_val_noise).T\n",
    "model_pool.val_gaussian_pred_probs = model_pool.get_individual_probabilities(x_val_noise)\n",
    "del x_train_noise, x_val_noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f32265",
   "metadata": {},
   "source": [
    "### Uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bedd4c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_noise = train_noise.add_uniform_noise(add_nosie_feats_float)\n",
    "x_train_noise = train_noise.add_categorical_noise(add_nosie_feats_categorical)\n",
    "\n",
    "x_val_noise = val_noise.add_uniform_noise(add_nosie_feats_float)\n",
    "x_val_noise = val_noise.add_categorical_noise(add_nosie_feats_categorical)\n",
    "\n",
    "model_pool.train_uniform_preds = model_pool.get_individual_predictions(x_train_noise).T\n",
    "model_pool.train_uniform_pred_probs = model_pool.get_individual_probabilities(x_train_noise)\n",
    "\n",
    "model_pool.val_uniform_preds = model_pool.get_individual_predictions(x_val_noise).T\n",
    "model_pool.val_uniform_pred_probs = model_pool.get_individual_probabilities(x_val_noise)\n",
    "del x_train_noise, x_val_noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a206de",
   "metadata": {},
   "source": [
    "### Laplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df34d826",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_noise = train_noise.add_laplace_noise(add_nosie_feats_float)\n",
    "x_train_noise = train_noise.add_categorical_noise(add_nosie_feats_categorical)\n",
    "\n",
    "x_val_noise = val_noise.add_laplace_noise(add_nosie_feats_float)\n",
    "x_val_noise = val_noise.add_categorical_noise(add_nosie_feats_categorical)\n",
    "\n",
    "model_pool.train_laplace_preds = model_pool.get_individual_predictions(x_train_noise).T\n",
    "model_pool.train_laplace_pred_probs = model_pool.get_individual_probabilities(x_train_noise)\n",
    "\n",
    "model_pool.val_laplace_preds = model_pool.get_individual_predictions(x_val_noise).T\n",
    "model_pool.val_laplace_pred_probs = model_pool.get_individual_probabilities(x_val_noise)\n",
    "del x_train_noise, x_val_noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13b2fa0",
   "metadata": {},
   "source": [
    "### Dropout noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de41c9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_noise = train_noise.add_dropout_noise(add_nosie_feats_float)\n",
    "x_train_noise = train_noise.add_categorical_noise(add_nosie_feats_categorical)\n",
    "\n",
    "x_val_noise = val_noise.add_dropout_noise(add_nosie_feats_float)\n",
    "x_val_noise = val_noise.add_categorical_noise(add_nosie_feats_categorical)\n",
    "\n",
    "model_pool.train_dropout_preds = model_pool.get_individual_predictions(x_train_noise).T\n",
    "model_pool.train_dropout_pred_probs = model_pool.get_individual_probabilities(x_train_noise)\n",
    "\n",
    "model_pool.val_dropout_preds = model_pool.get_individual_predictions(x_val_noise).T\n",
    "model_pool.val_dropout_pred_probs = model_pool.get_individual_probabilities(x_val_noise)\n",
    "del x_train_noise, x_val_noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f5954f",
   "metadata": {},
   "source": [
    "### Boundary Shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "397b22c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_noise = train_noise.add_concept_shift(shift_type=\"boundary_shift\",\n",
    "                                             shift_params={'feature_col':float_cols[0]})\n",
    "x_train_noise = train_noise.add_categorical_noise(add_nosie_feats_categorical)\n",
    "\n",
    "x_val_noise = train_noise.add_concept_shift(shift_type=\"boundary_shift\",\n",
    "                                             shift_params={'feature_col':float_cols[0]})\n",
    "x_val_noise = val_noise.add_categorical_noise(add_nosie_feats_categorical)\n",
    "\n",
    "model_pool.train_boundaryshift_preds = model_pool.get_individual_predictions(x_train_noise).T\n",
    "model_pool.train_boundaryshift_pred_probs = model_pool.get_individual_probabilities(x_train_noise)\n",
    "\n",
    "model_pool.val_boundaryshift_preds = model_pool.get_individual_predictions(x_val_noise).T\n",
    "model_pool.val_boundaryshift_pred_probs = model_pool.get_individual_probabilities(x_val_noise)\n",
    "del x_train_noise, x_val_noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ab8c85",
   "metadata": {},
   "source": [
    "### Scaling Shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ca9dd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_noise = train_noise.add_covariate_shift(add_nosie_feats_float, \n",
    "                                shift_type='scaling',\n",
    "                                shift_params = {'scale_factor':1.2})\n",
    "\n",
    "\n",
    "x_val_noise = train_noise.add_covariate_shift(add_nosie_feats_float, \n",
    "                                shift_type='scaling',\n",
    "                                shift_params = {'scale_factor':1.2})\n",
    "\n",
    "model_pool.train_upscaleshift_preds = model_pool.get_individual_predictions(x_train_noise).T\n",
    "model_pool.train_upscaleshift_pred_probs = model_pool.get_individual_probabilities(x_train_noise)\n",
    "\n",
    "model_pool.val_upscaleshift_preds = model_pool.get_individual_predictions(x_val_noise).T\n",
    "model_pool.val_upscaleshift_pred_probs = model_pool.get_individual_probabilities(x_val_noise)\n",
    "del x_train_noise, x_val_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e82ed6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_noise = train_noise.add_covariate_shift(add_nosie_feats_float, \n",
    "                                shift_type='scaling',\n",
    "                                shift_params = {'scale_factor':0.8})\n",
    "\n",
    "\n",
    "x_val_noise = train_noise.add_covariate_shift(add_nosie_feats_float, \n",
    "                                shift_type='scaling',\n",
    "                              shift_params = {'scale_factor':0.8})\n",
    "\n",
    "model_pool.train_downscaleshift_preds = model_pool.get_individual_predictions(x_train_noise).T\n",
    "model_pool.train_downscaleshift_pred_probs = model_pool.get_individual_probabilities(x_train_noise)\n",
    "\n",
    "model_pool.val_downscaleshift_preds = model_pool.get_individual_predictions(x_val_noise).T\n",
    "model_pool.val_downscaleshift_pred_probs = model_pool.get_individual_probabilities(x_val_noise)\n",
    "del x_train_noise, x_val_noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56dbed4",
   "metadata": {},
   "source": [
    "### Distribution shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f23bc425",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_noise = train_noise.add_covariate_shift(add_nosie_feats_float, \n",
    "                                shift_type='distribution',\n",
    "                                shift_params = {'dist_type':'uniform'})\n",
    "x_val_noise = val_noise.add_covariate_shift(add_nosie_feats_float, \n",
    "                                shift_type='distribution',\n",
    "                                shift_params = {'dist_type':'uniform'})\n",
    "\n",
    "model_pool.train_distshiftuniform_preds = model_pool.get_individual_predictions(x_train_noise).T\n",
    "model_pool.train_distshiftuniform_pred_probs = model_pool.get_individual_probabilities(x_train_noise)\n",
    "\n",
    "model_pool.val_distshiftuniform_preds = model_pool.get_individual_predictions(x_val_noise).T\n",
    "model_pool.val_distshiftuniform_pred_probs = model_pool.get_individual_probabilities(x_val_noise)\n",
    "del x_train_noise, x_val_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "36c9cf3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_noise = train_noise.add_covariate_shift(add_nosie_feats_float, \n",
    "                                shift_type='distribution',\n",
    "                                shift_params = {'dist_type':'normal'})\n",
    "\n",
    "\n",
    "x_val_noise = val_noise.add_covariate_shift(add_nosie_feats_float, \n",
    "                                shift_type='distribution',\n",
    "                                shift_params = {'dist_type':'normal'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d013914a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_noise = train_noise.add_covariate_shift(add_nosie_feats_float, \n",
    "                                shift_type='distribution',\n",
    "                                shift_params = {'dist_type':'uniform'})\n",
    "x_val_noise = val_noise.add_covariate_shift(add_nosie_feats_float, \n",
    "                                shift_type='distribution',\n",
    "                                shift_params = {'dist_type':'uniform'})\n",
    "\n",
    "model_pool.train_distshiftgaussian_preds = model_pool.get_individual_predictions(x_train_noise).T\n",
    "model_pool.train_distshiftgaussian_pred_probs = model_pool.get_individual_probabilities(x_train_noise)\n",
    "\n",
    "model_pool.val_distshiftgaussian_preds = model_pool.get_individual_predictions(x_val_noise).T\n",
    "model_pool.val_distshiftgaussian_pred_probs = model_pool.get_individual_probabilities(x_val_noise)\n",
    "del x_train_noise, x_val_noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d875dc",
   "metadata": {},
   "source": [
    "### label Shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "453ac964",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_flipped = DataNoiseAdder.label_flip(y_train)\n",
    "y_val_flipped = DataNoiseAdder.label_flip(y_val_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cffeae66",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [x for x in dir(model_pool) if 'preds' in x]\n",
    "b = [x for x in dir(model_pool) if 'pred_' in x]\n",
    "attributes = [(a[i], b[i], a[i].split('_')[1]) for i in range(len(a))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e276a00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = [(a[i], b[i], a[i].split('_')[0]+'_'+a[i].split('_')[1]) for i in range(len(a))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4e292e06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 1., ..., 1., 0., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       [0., 1., 1., ..., 1., 0., 1.],\n",
       "       ...,\n",
       "       [0., 0., 1., ..., 1., 0., 0.],\n",
       "       [1., 1., 1., ..., 0., 1., 1.],\n",
       "       [0., 1., 1., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getattr(model_pool, 'val_upscaleshift_preds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e3ddbc1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('train_boundaryshift_preds',\n",
       "  'train_boundaryshift_pred_probs',\n",
       "  'train_boundaryshift'),\n",
       " ('train_distshiftgaussian_preds',\n",
       "  'train_distshiftgaussian_pred_probs',\n",
       "  'train_distshiftgaussian'),\n",
       " ('train_distshiftuniform_preds',\n",
       "  'train_distshiftuniform_pred_probs',\n",
       "  'train_distshiftuniform'),\n",
       " ('train_downscaleshift_preds',\n",
       "  'train_downscaleshift_pred_probs',\n",
       "  'train_downscaleshift'),\n",
       " ('train_dropout_preds', 'train_dropout_pred_probs', 'train_dropout'),\n",
       " ('train_gaussian_preds', 'train_gaussian_pred_probs', 'train_gaussian'),\n",
       " ('train_laplace_preds', 'train_laplace_pred_probs', 'train_laplace'),\n",
       " ('train_uniform_preds', 'train_uniform_pred_probs', 'train_uniform'),\n",
       " ('train_upscaleshift_preds',\n",
       "  'train_upscaleshift_pred_probs',\n",
       "  'train_upscaleshift'),\n",
       " ('val_boundaryshift_preds',\n",
       "  'val_boundaryshift_pred_probs',\n",
       "  'val_boundaryshift'),\n",
       " ('val_distshiftgaussian_preds',\n",
       "  'val_distshiftgaussian_pred_probs',\n",
       "  'val_distshiftgaussian'),\n",
       " ('val_distshiftuniform_preds',\n",
       "  'val_distshiftuniform_pred_probs',\n",
       "  'val_distshiftuniform'),\n",
       " ('val_downscaleshift_preds',\n",
       "  'val_downscaleshift_pred_probs',\n",
       "  'val_downscaleshift'),\n",
       " ('val_dropout_preds', 'val_dropout_pred_probs', 'val_dropout'),\n",
       " ('val_gaussian_preds', 'val_gaussian_pred_probs', 'val_gaussian'),\n",
       " ('val_laplace_preds', 'val_laplace_pred_probs', 'val_laplace'),\n",
       " ('val_uniform_preds', 'val_uniform_pred_probs', 'val_uniform'),\n",
       " ('val_upscaleshift_preds', 'val_upscaleshift_pred_probs', 'val_upscaleshift')]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88d22dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d48a26b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.23649784,  0.11253436,  0.89375719, ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       [ 0.57679816, -0.18336508,  0.89375719, ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       [-0.75096158, -0.66155009,  0.00225696, ...,  1.        ,\n",
       "         1.        ,  1.        ],\n",
       "       ...,\n",
       "       [-0.99991653, -0.78055703,  0.89375719, ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       [ 2.23649784,  0.24376558,  0.89375719, ...,  0.        ,\n",
       "         1.        ,  1.        ],\n",
       "       [-0.75096158, -0.82765646,  0.89375719, ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe8401b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
